{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073cd172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\PC\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: Hi! Type 'exit' to end the conversation.\n",
      "You: hiiiii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: hiya :D\n",
      "You: hii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: hi :D\n",
      "You: How are you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: I'm good, how are you?\n",
      "You: I am greate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: good :D\n",
      "You: so what do want to suggest?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: I dunno, I'm not really into anime\n",
      "You: what are you into then?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: I'm into anime, but I'm not into anime.\n",
      "You: Do you like talking with me?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: I do\n",
      "You: so can I tell you something?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: I'm not into anime\n",
      "You: Change the subject\n",
      "AI Chatbot: Sure, let's talk about something else! I'm listening.\n",
      "You: hiiiiiiiii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: Hey, you're that guy!\n",
      "You: How do you remember me?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: I don't. I just know you.\n",
      "You: Brooooo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: I'm not your bro, bro.\n",
      "You: suggest me a song by arijit singh\n",
      "Searching for songs by arijit singh...\n",
      "AI Chatbot: How about listening to 'Tujhe Kitna Chahne Lage (From \"Kabir Singh\")' by Arijit Singh?\n",
      "You: suggest me a movie starring by Sidharth malhotra\n",
      "AI Chatbot: How about watching 'Yodha'?\n",
      "You: you are the best \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chatbot: I'm not your bro, bro.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Set up Spotify API client\n",
    "client_id = \"5efcafaa1ddf4fb2a2808bce841c1b88\"  # Replace with your Spotify Client ID\n",
    "client_secret = \"0735f01a14c84c688504bca3367167f8\"  # Replace with your Spotify Client Secret\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# TMDb API Setup\n",
    "TMDB_API_KEY = '5ab369b78ced207af8e34061d64d9c8d'  # Replace with your TMDb API key\n",
    "TMDB_BASE_URL = 'https://api.themoviedb.org/3'\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"microsoft/DialoGPT-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "print(\"AI Chatbot: Hi! Type 'exit' to end the conversation.\")\n",
    "\n",
    "# Function to get movies by genre\n",
    "def get_movies_by_genre(genre_id, page=1):\n",
    "    url = f\"{TMDB_BASE_URL}/discover/movie?api_key={TMDB_API_KEY}&with_genres={genre_id}&page={page}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if data.get('results'):\n",
    "        movies = []\n",
    "        for movie in data['results']:\n",
    "            movies.append(f\"Title: {movie['title']}, Release Date: {movie['release_date']}, Overview: {movie['overview']}\")\n",
    "        return movies\n",
    "    else:\n",
    "        return [\"No movies found for this genre.\"]\n",
    "\n",
    "# Function to get movies by actor (returns just the first movie for simplicity)\n",
    "def get_movies_by_actor(actor_name, recommended_movies):\n",
    "    try:\n",
    "        search_url = f\"{TMDB_BASE_URL}/search/person?api_key={TMDB_API_KEY}&query={actor_name}\"\n",
    "        search_response = requests.get(search_url)\n",
    "        search_data = search_response.json()\n",
    "\n",
    "        if search_data.get('results'):\n",
    "            actor_id = search_data['results'][0]['id']\n",
    "            actor_movies_url = f\"{TMDB_BASE_URL}/person/{actor_id}/movie_credits?api_key={TMDB_API_KEY}\"\n",
    "            actor_movies_response = requests.get(actor_movies_url)\n",
    "            actor_movies_data = actor_movies_response.json()\n",
    "\n",
    "            # Return just the first movie, if not already recommended\n",
    "            for movie in actor_movies_data['cast']:\n",
    "                if movie['title'] not in recommended_movies:\n",
    "                    recommended_movies.append(movie['title'])\n",
    "                    return movie['title'], recommended_movies\n",
    "\n",
    "            return \"No more new movies found for this actor.\", recommended_movies\n",
    "        else:\n",
    "            return \"No movies found for this actor.\", recommended_movies\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching movies by actor: {e}\", recommended_movies\n",
    "\n",
    "# Function to get a list of song recommendations from a specific artist\n",
    "def get_artist_song_recommendations(artist_name, already_recommended):\n",
    "    print(f\"Searching for songs by {artist_name}...\")\n",
    "    results = sp.search(q=f'artist:{artist_name}', type='track', limit=10)\n",
    "\n",
    "    songs = [song for song in results['tracks']['items'] if song['name'] not in already_recommended]\n",
    "\n",
    "    if songs:\n",
    "        song = songs[0]\n",
    "        song_name = song['name']\n",
    "        artist_name = song['artists'][0]['name']\n",
    "        already_recommended.append(song_name)\n",
    "        return f\"How about listening to '{song_name}' by {artist_name}?\", already_recommended\n",
    "    else:\n",
    "        return f\"Sorry, I've run out of new songs by {artist_name}. Try another artist!\", already_recommended\n",
    "\n",
    "# Function to suggest songs based on the user's mood using Spotify search\n",
    "def get_song_based_on_mood(mood):\n",
    "    mood = mood.lower()\n",
    "\n",
    "    # Search moods related keywords or phrases to match the mood\n",
    "    mood_keywords = {\n",
    "        \"happy\": [\"happy\", \"joy\", \"upbeat\", \"cheerful\"],\n",
    "        \"sad\": [\"sad\", \"melancholy\", \"lonely\", \"blue\"],\n",
    "        \"energetic\": [\"energetic\", \"workout\", \"party\", \"dance\"],\n",
    "        \"chill\": [\"chill\", \"relaxed\", \"calm\", \"easy\"]\n",
    "    }\n",
    "\n",
    "    # Search Spotify for songs that match the mood keywords\n",
    "    if mood in mood_keywords:\n",
    "        search_results = []\n",
    "        for keyword in mood_keywords[mood]:\n",
    "            search_results += sp.search(q=keyword, type='track', limit=5)['tracks']['items']\n",
    "\n",
    "        if search_results:\n",
    "            song = search_results[0]\n",
    "            song_name = song['name']\n",
    "            artist_name = song['artists'][0]['name']\n",
    "            return f\"How about listening to '{song_name}' by {artist_name}? It's perfect for your mood!\", []\n",
    "        else:\n",
    "            return f\"Sorry, I couldn't find any songs for the mood '{mood}'.\", []\n",
    "    else:\n",
    "        return \"Sorry, I don't have song recommendations for that mood right now. Try a different mood!\", []\n",
    "\n",
    "# Predefined responses to improve conversation flow\n",
    "def handle_stressful_day(user_input):\n",
    "    stressful_keywords = [\"stress\", \"tired\", \"work\", \"busy\", \"exhausted\"]\n",
    "    if any(keyword in user_input for keyword in stressful_keywords):\n",
    "        return \"I'm really sorry to hear that! It sounds like you've had a tough day. Do you want to talk about it or listen to some relaxing music?\"\n",
    "    return None\n",
    "\n",
    "# Chat history storage\n",
    "chat_history_ids = None\n",
    "already_recommended_songs = []  # To store recommended songs to avoid repetition\n",
    "recommended_movies = []  # To store recommended movies to avoid repetition\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \").lower()\n",
    "\n",
    "    if user_input == \"exit\":\n",
    "        print(\"AI Chatbot: Bye! Have a nice day.\")\n",
    "        break\n",
    "\n",
    "    if \"change the subject\" in user_input:\n",
    "        print(\"AI Chatbot: Sure, let's talk about something else! I'm listening.\")\n",
    "        chat_history_ids = None  # Clear the chat history\n",
    "        continue\n",
    "\n",
    "    stress_response = handle_stressful_day(user_input)\n",
    "    if stress_response:\n",
    "        print(f\"AI Chatbot: {stress_response}\")\n",
    "        continue  # Skip DialoGPT response\n",
    "\n",
    "    # Check if the user asks for a song recommendation by a specific artist (e.g., \"suggest me a song by Shreya Ghosal\")\n",
    "    if \"suggest me a song by\" in user_input:\n",
    "        artist_name = user_input.replace(\"suggest me a song by\", \"\").strip()\n",
    "        if artist_name:\n",
    "            song_recommendation, already_recommended_songs = get_artist_song_recommendations(artist_name, already_recommended_songs)\n",
    "            print(f\"AI Chatbot: {song_recommendation}\")\n",
    "        else:\n",
    "            print(\"AI Chatbot: Please specify an artist for the song you'd like!\")\n",
    "        continue  # Skip DialoGPT response\n",
    "\n",
    "    # Check if the user asks for a song recommendation based on mood (e.g., \"suggest me happy song\")\n",
    "    if \"suggest me\" in user_input and \"song\" in user_input and \"by\" not in user_input:\n",
    "        mood = user_input.replace(\"suggest me\", \"\").replace(\"song\", \"\").strip()\n",
    "        if mood:\n",
    "            song_recommendation, _ = get_song_based_on_mood(mood)\n",
    "            print(f\"AI Chatbot: {song_recommendation}\")\n",
    "        else:\n",
    "            print(\"AI Chatbot: Please specify the mood for the song you'd like!\")\n",
    "        continue  # Skip DialoGPT response\n",
    "\n",
    "    # Check if the user asks for a movie recommendation (i.e., \"suggest me a movie starring\")\n",
    "    if \"suggest me a movie starring\" in user_input:\n",
    "        actor_name = user_input.replace(\"suggest me a movie starring\", \"\").strip()\n",
    "        if actor_name:\n",
    "            movie, recommended_movies = get_movies_by_actor(actor_name, recommended_movies)  # Get just one movie\n",
    "            print(f\"AI Chatbot: How about watching '{movie}'?\")\n",
    "        else:\n",
    "            print(\"AI Chatbot: Please specify an actor you'd like movie recommendations for!\")\n",
    "        continue  # Skip DialoGPT response\n",
    "\n",
    "    # Tokenize input and encode the user's input for conversational purposes\n",
    "    new_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # Append the new input to the chat history (if exists)\n",
    "    if chat_history_ids is not None:\n",
    "        bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1)\n",
    "    else:\n",
    "        bot_input_ids = new_input_ids\n",
    "\n",
    "    # Generate response using DialoGPT\n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decode and print the bot's response\n",
    "    bot_response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    print(f\"AI Chatbot: {bot_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df201b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
